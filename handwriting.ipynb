{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1840441,"sourceType":"datasetVersion","datasetId":1094263}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:14.889215Z","iopub.execute_input":"2025-11-01T12:40:14.889480Z","iopub.status.idle":"2025-11-01T12:40:14.894491Z","shell.execute_reply.started":"2025-11-01T12:40:14.889461Z","shell.execute_reply":"2025-11-01T12:40:14.893865Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"cd /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:14.895593Z","iopub.execute_input":"2025-11-01T12:40:14.896125Z","iopub.status.idle":"2025-11-01T12:40:14.910842Z","shell.execute_reply.started":"2025-11-01T12:40:14.896106Z","shell.execute_reply":"2025-11-01T12:40:14.910067Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"pip install jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:14.911500Z","iopub.execute_input":"2025-11-01T12:40:14.911665Z","iopub.status.idle":"2025-11-01T12:40:21.090199Z","shell.execute_reply.started":"2025-11-01T12:40:14.911645Z","shell.execute_reply":"2025-11-01T12:40:21.089455Z"}},"outputs":[{"name":"stdout","text":"Collecting jiwer\n  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.0)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\nDownloading jiwer-4.0.0-py3-none-any.whl (23 kB)\nDownloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\nSuccessfully installed jiwer-4.0.0 rapidfuzz-3.14.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!mkdir -p Handwriting","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.091916Z","iopub.execute_input":"2025-11-01T12:40:21.092467Z","iopub.status.idle":"2025-11-01T12:40:21.212127Z","shell.execute_reply.started":"2025-11-01T12:40:21.092444Z","shell.execute_reply":"2025-11-01T12:40:21.211392Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"cd /kaggle/working/Handwriting/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.213255Z","iopub.execute_input":"2025-11-01T12:40:21.213517Z","iopub.status.idle":"2025-11-01T12:40:21.219913Z","shell.execute_reply.started":"2025-11-01T12:40:21.213493Z","shell.execute_reply":"2025-11-01T12:40:21.219249Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Handwriting\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!mkdir -p data notebooks src models outputs checkpoints configs ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:49:34.872059Z","iopub.execute_input":"2025-11-01T12:49:34.872487Z","iopub.status.idle":"2025-11-01T12:49:35.003959Z","shell.execute_reply.started":"2025-11-01T12:49:34.872461Z","shell.execute_reply":"2025-11-01T12:49:35.003042Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"!mkdir -p src/utils ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.220687Z","iopub.execute_input":"2025-11-01T12:40:21.220915Z","iopub.status.idle":"2025-11-01T12:40:21.346114Z","shell.execute_reply.started":"2025-11-01T12:40:21.220895Z","shell.execute_reply":"2025-11-01T12:40:21.345260Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!touch README.md requirements.txt main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.347163Z","iopub.execute_input":"2025-11-01T12:40:21.347453Z","iopub.status.idle":"2025-11-01T12:40:21.468330Z","shell.execute_reply.started":"2025-11-01T12:40:21.347430Z","shell.execute_reply":"2025-11-01T12:40:21.467533Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"%%writefile requirements.txt\n\ntorch>=2.0\ntorchvision\nnumpy\npillow\ntqdm\npyyaml\neditdistance\npython-Levenshtein   # optional, faster for WER/CER\nscikit-learn         # for train/test split helpers if needed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.469354Z","iopub.execute_input":"2025-11-01T12:40:21.469647Z","iopub.status.idle":"2025-11-01T12:40:21.475343Z","shell.execute_reply.started":"2025-11-01T12:40:21.469624Z","shell.execute_reply":"2025-11-01T12:40:21.474621Z"}},"outputs":[{"name":"stdout","text":"Overwriting requirements.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install -r requirements.txt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:40:21.476054Z","iopub.execute_input":"2025-11-01T12:40:21.476709Z","iopub.status.idle":"2025-11-01T12:41:31.885801Z","shell.execute_reply.started":"2025-11-01T12:40:21.476681Z","shell.execute_reply":"2025-11-01T12:41:31.885053Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.3.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (6.0.3)\nRequirement already satisfied: editdistance in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.8.1)\nCollecting python-Levenshtein (from -r requirements.txt (line 9))\n  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (2025.9.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->-r requirements.txt (line 2))\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->-r requirements.txt (line 2)) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->-r requirements.txt (line 4)) (2.4.1)\nCollecting Levenshtein==0.27.1 (from python-Levenshtein->-r requirements.txt (line 9))\n  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from Levenshtein==0.27.1->python-Levenshtein->-r requirements.txt (line 9)) (3.14.3)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->-r requirements.txt (line 2)) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 4)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->-r requirements.txt (line 4)) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->-r requirements.txt (line 4)) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->-r requirements.txt (line 4)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->-r requirements.txt (line 4)) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\nDownloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Levenshtein, python-Levenshtein, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Levenshtein-0.27.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-Levenshtein-0.27.1\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load IAM line-level dataset\ndataset = load_dataset(\"Teklia/IAM-line\")\nprint(dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:41:31.888819Z","iopub.execute_input":"2025-11-01T12:41:31.889027Z","iopub.status.idle":"2025-11-01T12:41:39.383391Z","shell.execute_reply.started":"2025-11-01T12:41:31.889008Z","shell.execute_reply":"2025-11-01T12:41:39.382790Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d0ce5f5d0da456a97d98d3798764cb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"558ad9d249e4459eae79f5df004e467c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation.parquet:   0%|          | 0.00/24.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cc2238918bd412ea76019567e46c21a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test.parquet:   0%|          | 0.00/73.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c28bc40f8a4d470ba18b42558418f40a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/6482 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd384905cc246cebce7915741810fce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/976 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25b94e4417c44b76991b103996003b43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2915 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d022c43af6724a3dace96bf6ed213a67"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['image', 'text'],\n        num_rows: 6482\n    })\n    validation: Dataset({\n        features: ['image', 'text'],\n        num_rows: 976\n    })\n    test: Dataset({\n        features: ['image', 'text'],\n        num_rows: 2915\n    })\n})\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\nsample = dataset['train'][0]\nprint(\"Text:\", sample['text'])\nplt.imshow(sample['image'])\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:41:39.384334Z","iopub.execute_input":"2025-11-01T12:41:39.384801Z","iopub.status.idle":"2025-11-01T12:41:39.525144Z","shell.execute_reply.started":"2025-11-01T12:41:39.384782Z","shell.execute_reply":"2025-11-01T12:41:39.524480Z"}},"outputs":[{"name":"stdout","text":"Text: put down a resolution on the subject\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import os\n\nbase_dir = \"/kaggle/working/Handwriting/iam_dataset\"\nos.makedirs(base_dir, exist_ok=True)\n\nfor split in [\"train\", \"validation\", \"test\"]:\n    split_dir = os.path.join(base_dir, split)\n    os.makedirs(split_dir, exist_ok=True)\n    \n    txt_path = os.path.join(split_dir, f\"{split}.txt\")\n    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n        for i, sample in enumerate(dataset[split]):\n            img = sample[\"image\"]\n            text = sample[\"text\"].strip()\n            img_path = os.path.join(split_dir, f\"{split}_{i}.png\")\n            img.save(img_path)\n            f.write(f\"{img_path}\\t{text}\\n\")\n\nprint(\"✅ Dataset saved at:\", base_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:41:39.525931Z","iopub.execute_input":"2025-11-01T12:41:39.526216Z","iopub.status.idle":"2025-11-01T12:45:56.441861Z","shell.execute_reply.started":"2025-11-01T12:41:39.526171Z","shell.execute_reply":"2025-11-01T12:45:56.441211Z"}},"outputs":[{"name":"stdout","text":"✅ Dataset saved at: /kaggle/working/Handwriting/iam_dataset\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile src/utils/tokenizer.py\n\n\nimport string\n\nclass Tokenizer:\n    def __init__(self, additional_chars=\"\"):\n        # define charset: lowercase letters, digits, punctuation, space\n        base = string.ascii_lowercase + string.digits + string.punctuation + \" \"\n        base += additional_chars\n        # CTC needs a blank token; we'll index blank as 0\n        # So we add characters starting from index 1\n        self.chars = sorted(list(set(base)))\n        # keep blank at index 0 for CTC\n        self.blank_index = 0\n        self.idx_to_char = {0: \"\"}\n        next_idx = 1\n        for c in self.chars:\n            self.idx_to_char[next_idx] = c\n            next_idx += 1\n        self.char_to_idx = {c: i for i, c in self.idx_to_char.items() if i != 0}\n        # create full maps (including blank)\n        self.char_to_idx_with_blank = {**{ \"\": 0 }, **self.char_to_idx}\n\n    def encode(self, text):\n        # lower and strip optional\n        seq = []\n        for ch in text.lower():\n            if ch in self.char_to_idx:\n                seq.append(self.char_to_idx[ch])\n            # else skip unknown chars (could map them to space)\n        return seq\n\n    def decode(self, indices):\n        # indices are integers from CTC decode raw output\n        # collapse repeats and remove blanks(0)\n        out = []\n        prev = None\n        for idx in indices:\n            if idx == prev:\n                prev = idx\n                continue\n            if idx != 0:\n                out.append(self.idx_to_char.get(idx, \"\"))\n            prev = idx\n        return \"\".join(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.442748Z","iopub.execute_input":"2025-11-01T12:45:56.443007Z","iopub.status.idle":"2025-11-01T12:45:56.448305Z","shell.execute_reply.started":"2025-11-01T12:45:56.442985Z","shell.execute_reply":"2025-11-01T12:45:56.447636Z"}},"outputs":[{"name":"stdout","text":"Writing src/utils/tokenizer.py\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%writefile src/data.py\n\n\nimport os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport numpy as np\nimport torchvision.transforms as T\n\nclass IAMLineDataset(Dataset): \n    \"\"\"\n    Expects a transcript file (tab-separated or space-separated) with entries:\n    image_path<TAB>transcription\n    and the images under a base folder.\n    Adapt read_transcripts() to match your IAM transcript format.\n    \"\"\"\n    def __init__(self, img_base, transcript_file, tokenizer, img_h=64, transforms=None, max_width=1600):\n        self.img_base = img_base\n        self.tokenizer = tokenizer\n        self.img_h = img_h\n        self.max_width = max_width\n        self.transforms = transforms\n        self.samples = self.read_transcripts(transcript_file)\n\n    def read_transcripts(self, transcript_file):\n        samples = []\n        with open(transcript_file, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                if not line: continue\n                # Format depends on your transcripts. Common format: <image_relative_path> <transcription>\n                # If line contains a tab:\n                if \"\\t\" in line:\n                    img_rel, trans = line.split(\"\\t\", 1)\n                else:\n                    parts = line.split(\" \", 1)\n                    if len(parts) < 2:\n                        continue\n                    img_rel, trans = parts[0], parts[1]\n                if os.path.isabs(img_rel):\n                    img_path = img_rel\n                else:\n                    img_path = os.path.join(self.img_base, img_rel)\n\n                if os.path.exists(img_path):\n                    samples.append((img_path, trans))\n        return samples\n\n    def __len__(self):\n        return len(self.samples)\n\n    def load_image(self, path):\n        img = Image.open(path).convert(\"L\")  # grayscale\n        return img\n\n    def resize_keep_aspect(self, img, target_height):\n        w, h = img.size\n        new_h = target_height\n        new_w = int(w * (new_h / float(h)))\n        if new_w > self.max_width:\n            new_w = self.max_width\n        img = img.resize((new_w, new_h), Image.BILINEAR)\n        return img\n\n    def __getitem__(self, idx):\n        img_path, transcription = self.samples[idx]\n        img = self.load_image(img_path)\n        img = self.resize_keep_aspect(img, self.img_h)\n        if self.transforms:\n            img = self.transforms(img)\n        else:\n            # default: to tensor and normalize [0,1]\n            transform = T.Compose([T.ToTensor(),])  # shape: (1, H, W)\n            img = transform(img)\n        # encode target\n        target = torch.LongTensor(self.tokenizer.encode(transcription))\n        return img, target, transcription\n\ndef collate_fn(batch):\n    \"\"\"\n    batch: list of (img_tensor, target_tensor, transcription)\n    For CTC, we need:\n      - padded batch images (pad widths)\n      - targets concatenated, and target_lengths\n      - input_lengths (sequence length produced by CNN/LSTM later) — computed in train loop from model output\n    We'll return the raw images padded to same width and the target concatenation/lengths.\n    \"\"\"\n    imgs = [b[0] for b in batch]\n    targets = [b[1] for b in batch]\n    trans = [b[2] for b in batch]\n    max_w = max([img.shape[-1] for img in imgs])\n    c = imgs[0].shape[0]\n    h = imgs[0].shape[1]\n    padded = torch.zeros((len(imgs), c, h, max_w), dtype=imgs[0].dtype)\n    for i, img in enumerate(imgs):\n        padded[i, :, :, :img.shape[-1]] = img\n    # concat targets\n    target_lengths = torch.tensor([t.shape[0] for t in targets], dtype=torch.long)\n    targets_concat = torch.cat(targets) if len(targets) > 0 else torch.LongTensor([])\n    return padded, targets_concat, target_lengths, trans\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.449011Z","iopub.execute_input":"2025-11-01T12:45:56.449266Z","iopub.status.idle":"2025-11-01T12:45:56.465909Z","shell.execute_reply.started":"2025-11-01T12:45:56.449244Z","shell.execute_reply":"2025-11-01T12:45:56.465326Z"}},"outputs":[{"name":"stdout","text":"Writing src/data.py\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"%%writefile src/model.py\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CRNN(nn.Module):\n    def __init__(self, n_classes, img_h=64, channels=1, lstm_hidden=256, lstm_layers=2):\n        super().__init__()\n        \n        # --- Convolutional Backbone ---\n        self.cnn = nn.Sequential(\n            nn.Conv2d(channels, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d((2, 2)),  # H/2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d((2, 2)),        # H/4\n            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d((2, 1)),       # H/8\n            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(), nn.BatchNorm2d(512),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d((2, 1)),       # H/16\n            nn.Conv2d(512, 512, kernel_size=2), nn.ReLU()                                        # ~H=1\n        )\n\n        # --- RNN Layers ---\n        # After CNN, height ≈ 1, so features per time-step = 512\n        rnn_input_size = 1536 #512\n        self.rnn = nn.LSTM(\n            rnn_input_size,\n            lstm_hidden,\n            num_layers=lstm_layers,\n            bidirectional=True,\n            batch_first=True\n        )\n        \n        self.fc = nn.Linear(lstm_hidden * 2, n_classes)  # Bidirectional LSTM doubles hidden size\n        self.log_softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self, x):\n        # x: (B, C, H, W)\n        conv = self.cnn(x)                  # (B, C, H', W')\n        B, C, H, W = conv.size()\n        \n        # Collapse height dimension\n        conv = conv.permute(0, 3, 1, 2)     # (B, W, C, H)\n        conv = conv.reshape(B, W, C * H)    # (B, W, C*H)\n        \n        # RNN processing\n        rnn_out, _ = self.rnn(conv)         # (B, W, hidden*2)\n        out = self.fc(rnn_out)              # (B, W, n_classes)\n        log_probs = self.log_softmax(out)   # for CTC Loss\n        return log_probs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.466577Z","iopub.execute_input":"2025-11-01T12:45:56.466807Z","iopub.status.idle":"2025-11-01T12:45:56.482750Z","shell.execute_reply.started":"2025-11-01T12:45:56.466782Z","shell.execute_reply":"2025-11-01T12:45:56.482237Z"}},"outputs":[{"name":"stdout","text":"Writing src/model.py\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"%%writefile src/train.py\nimport os\nimport torch\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport yaml\n\nimport sys\n# get the current script directory (like /kaggle/working/handwriting_recognition_pipeline/src)\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\n# go up one level to reach project root\nproject_root = os.path.dirname(current_dir)\n# add project root to sys.path\nsys.path.append(project_root)\n\nfrom src.data import IAMLineDataset, collate_fn\nfrom src.model import CRNN\nfrom src.utils.tokenizer import Tokenizer\nfrom src.utils.metrics import cer, wer\n\n\ndef train(cfg):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Tokenizer\n    tokenizer = Tokenizer()\n\n    # Datasets\n    transforms = None\n    train_ds = IAMLineDataset(\n        cfg[\"data\"][\"img_base\"], \n        cfg[\"data\"][\"train_transcript\"], \n        tokenizer, \n        img_h=cfg[\"data\"][\"img_h\"], \n        transforms=transforms\n    )\n    val_ds = IAMLineDataset(\n        cfg[\"data\"][\"img_base\"], \n        cfg[\"data\"][\"val_transcript\"], \n        tokenizer, \n        img_h=cfg[\"data\"][\"img_h\"], \n        transforms=transforms\n    )\n\n    train_loader = DataLoader(train_ds, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_ds, batch_size=cfg[\"training\"][\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n\n    # Model, Optimizer, Scheduler, Loss\n    n_classes = len(tokenizer.idx_to_char)\n    model = CRNN(n_classes=n_classes, img_h=cfg[\"data\"][\"img_h\"]).to(device)\n\n    optimizer = Adam(model.parameters(), lr=float(cfg[\"training\"][\"lr\"]))\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=float(cfg[\"training\"][\"lr\"]) * 10,  # can adjust multiplier\n        steps_per_epoch=len(train_loader),\n        epochs=cfg[\"training\"][\"epochs\"]\n    )\n\n    # Proper CTC setup\n    blank_token_id = getattr(tokenizer, \"blank_token_id\", 0)  # fallback to 0 if not defined\n    ctc_loss = nn.CTCLoss(blank=blank_token_id, zero_infinity=True)\n\n\n    # AMP (mixed precision)\n    scaler = torch.cuda.amp.GradScaler()\n\n    best_val_cer = float(\"inf\")\n    downsample_factor = 4  # adjust if model architecture changes\n\n    for epoch in range(cfg[\"training\"][\"epochs\"]):\n        model.train()\n        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg['training']['epochs']} [Train]\")\n        total_train_loss = 0.0\n\n        for imgs, targets_concat, target_lengths, trans in loop:\n            imgs = imgs.to(device)\n            targets_concat = targets_concat.to(device)\n\n            optimizer.zero_grad()\n\n            with torch.cuda.amp.autocast():\n                log_probs = model(imgs)  # (B, T, C)\n                log_probs = torch.nn.functional.log_softmax(log_probs, dim=2)\n                B, T, C = log_probs.shape\n                input_lengths = torch.full((B,), T, dtype=torch.long)\n                log_probs_t = log_probs.permute(1, 0, 2)\n                loss = ctc_loss(log_probs_t, targets_concat, input_lengths, target_lengths)\n\n            # Scaled backward\n            scaler.scale(loss).backward()\n\n            # Gradient clipping\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n\n            total_train_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n\n        avg_train_loss = total_train_loss / len(train_loader)\n        print(f\"\\nEpoch {epoch+1} | Avg Train Loss: {avg_train_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n\n        # Validation\n        model.eval()\n        total_cer = 0.0\n        total_wer = 0.0\n        n_eval = 0\n        with torch.no_grad():\n            for imgs, targets_concat, target_lengths, trans in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n                imgs = imgs.to(device)\n                with torch.cuda.amp.autocast():\n                    log_probs = model(imgs)\n                    probs = torch.exp(log_probs)\n                    preds = probs.argmax(dim=2)\n\n                for i in range(preds.shape[0]):\n                    seq = preds[i].cpu().tolist()\n                    pred_text = tokenizer.decode(seq)\n                    gt_text = trans[i].lower()\n                    total_cer += cer(pred_text, gt_text)\n                    total_wer += wer(pred_text, gt_text)\n                    n_eval += 1\n\n        avg_cer = total_cer / max(1, n_eval)\n        avg_wer = total_wer / max(1, n_eval)\n        print(f\"Epoch {epoch+1} | Val CER: {avg_cer:.4f} | Val WER: {avg_wer:.4f}\")\n\n        # Save best checkpoint\n        if avg_cer < best_val_cer:\n            best_val_cer = avg_cer\n            os.makedirs(os.path.dirname(cfg[\"training\"][\"checkpoint_path\"]), exist_ok=True)\n            torch.save(\n                {\n                    \"model_state\": model.state_dict(),\n                    \"tokenizer\": tokenizer.__dict__,\n                },\n                cfg[\"training\"][\"checkpoint_path\"]\n            )\n            print(f\"✅ Saved best checkpoint at {cfg['training']['checkpoint_path']} (CER={best_val_cer:.4f})\")\n\n    print(\"\\nTraining completed successfully ✅\")\n\n\nif __name__ == \"__main__\":\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--config\", type=str, required=True)\n    args = parser.parse_args()\n\n    with open(args.config) as f:\n        cfg = yaml.safe_load(f)\n\n    train(cfg)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.483380Z","iopub.execute_input":"2025-11-01T12:45:56.483644Z","iopub.status.idle":"2025-11-01T12:45:56.500868Z","shell.execute_reply.started":"2025-11-01T12:45:56.483629Z","shell.execute_reply":"2025-11-01T12:45:56.500164Z"}},"outputs":[{"name":"stdout","text":"Writing src/train.py\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"%%writefile src/utils/metrics.py\n\n\nimport editdistance\n\ndef cer(s1, s2):\n    \"\"\"Character Error Rate\"\"\"\n    if len(s2) == 0:\n        return 0.0 if len(s1) == 0 else 1.0\n    dist = editdistance.eval(s1, s2)\n    return dist / max(1, len(s2))\n\ndef wer(s1, s2):\n    \"\"\"Word Error Rate: tokenizes on whitespace\"\"\"\n    w1 = s1.split()\n    w2 = s2.split()\n    if len(w2) == 0:\n        return 0.0 if len(w1) == 0 else 1.0\n    dist = editdistance.eval(w1, w2)\n    return dist / max(1, len(w2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.501709Z","iopub.execute_input":"2025-11-01T12:45:56.501907Z","iopub.status.idle":"2025-11-01T12:45:56.516467Z","shell.execute_reply.started":"2025-11-01T12:45:56.501893Z","shell.execute_reply":"2025-11-01T12:45:56.515888Z"}},"outputs":[{"name":"stdout","text":"Writing src/utils/metrics.py\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"%%writefile configs/default.yaml\n\ndata:\n  img_base: \"/kaggle/working/Handwriting/iam_dataset\"\n  train_transcript: \"/kaggle/working/Handwriting/iam_dataset/train/train.txt\"\n  val_transcript: \"/kaggle/working/Handwriting/iam_dataset/validation/validation.txt\"\n  img_h: 64\n\n\ntraining:\n  batch_size: 8\n  lr: 1e-4\n  epochs: 30\n  checkpoint_path: \"checkpoints/best.pt\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:50:30.113340Z","iopub.execute_input":"2025-11-01T12:50:30.113642Z","iopub.status.idle":"2025-11-01T12:50:30.119547Z","shell.execute_reply.started":"2025-11-01T12:50:30.113616Z","shell.execute_reply":"2025-11-01T12:50:30.118719Z"}},"outputs":[{"name":"stdout","text":"Writing configs/default.yaml\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"%%writefile src/utils/beam_search.py\n\nimport torch\nimport numpy as np\n\ndef beam_search_decode(log_probs, beam_width=5, blank_idx=0):\n    \"\"\"\n    Performs beam search decoding for a batch of CTC outputs.\n\n    Args:\n        log_probs: Tensor of shape (T, C) - log probabilities per time step.\n        beam_width: Number of beams to keep at each time step.\n        blank_idx: Index representing the blank token in CTC.\n\n    Returns:\n        Best decoded string indices (list of int).\n    \"\"\"\n    T, C = log_probs.shape\n    beams = [(tuple(), 0)]  # (sequence, score)\n\n    for t in range(T):\n        new_beams = {}\n        for seq, score in beams:\n            for c in range(C):\n                new_seq = seq if c == blank_idx else seq + (c,)\n                new_score = score + log_probs[t, c].item()\n\n                if new_seq not in new_beams or new_score > new_beams[new_seq]:\n                    new_beams[new_seq] = new_score\n\n        # keep only top-k beams\n        beams = sorted(new_beams.items(), key=lambda x: x[1], reverse=True)[:beam_width]\n\n    # best sequence (highest score)\n    best_seq, _ = beams[0]\n\n    # collapse repeated characters\n    collapsed = []\n    prev = None\n    for c in best_seq:\n        if c != prev and c != blank_idx:\n            collapsed.append(c)\n        prev = c\n\n    return collapsed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T14:15:55.190960Z","iopub.execute_input":"2025-11-01T14:15:55.191661Z","iopub.status.idle":"2025-11-01T14:15:55.197462Z","shell.execute_reply.started":"2025-11-01T14:15:55.191633Z","shell.execute_reply":"2025-11-01T14:15:55.196744Z"}},"outputs":[{"name":"stdout","text":"Writing src/utils/beam_search.py\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"%%writefile src/eval.py\n\nimport torch\nimport argparse\nimport os\nimport sys\n\n# get the current script directory (like /kaggle/working/Handwriting/src)\ncurrent_dir = os.path.dirname(os.path.abspath(__file__))\nproject_root = os.path.dirname(current_dir)\nsys.path.append(project_root)\n\nfrom src.data import IAMLineDataset, collate_fn\nfrom src.model import CRNN\nfrom src.utils.tokenizer import Tokenizer\nfrom src.utils.metrics import cer, wer\nfrom src.utils.beam_search import beam_search_decode  # ✅ Added import\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n\ndef evaluate(checkpoint_path, img_base, val_transcript, img_h=64, batch_size=8, beam_width=5):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Load checkpoint\n    ckpt = torch.load(checkpoint_path, map_location=device)\n    tokenizer = Tokenizer()\n    model = CRNN(n_classes=len(tokenizer.idx_to_char), img_h=img_h)\n    model.load_state_dict(ckpt[\"model_state\"])\n    model = model.to(device)\n    model.eval()\n\n    val_ds = IAMLineDataset(img_base, val_transcript, tokenizer, img_h=img_h)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, collate_fn=collate_fn)\n\n    total_cer, total_wer = 0.0, 0.0\n    n_samples = 0\n    exact_matches = 0\n\n    with torch.no_grad():\n        for imgs, _, _, texts in tqdm(val_loader, desc=f\"Evaluating (Beam width={beam_width})\"):\n            imgs = imgs.to(device)\n            log_probs = model(imgs).cpu()  # shape: (B, T, C)\n\n            preds = []\n            for i in range(log_probs.shape[0]):\n                seq = beam_search_decode(log_probs[i], beam_width=beam_width)\n                preds.append(seq)\n\n            for i in range(len(preds)):\n                pred_text = tokenizer.decode(preds[i])\n                gt_text = texts[i].lower().strip()\n\n                total_cer += cer(pred_text, gt_text)\n                total_wer += wer(pred_text, gt_text)\n                n_samples += 1\n\n                if pred_text == gt_text:\n                    exact_matches += 1\n\n    print(f\"\\nAverage CER: {total_cer / n_samples:.4f}\")\n    print(f\"Average WER: {total_wer / n_samples:.4f}\")\n    print(f\"Sequence Accuracy: {exact_matches / n_samples:.4f}\")\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--checkpoint\", type=str, required=True)\n    parser.add_argument(\"--img_base\", type=str, default=\"/kaggle/working/Handwriting/iam_dataset\")\n    parser.add_argument(\"--val_transcript\", type=str, default=\"/kaggle/working/Handwriting/iam_dataset/validation/validation.txt\")\n    parser.add_argument(\"--beam_width\", type=int, default=5, help=\"Beam width for beam search decoding\")\n\n    args = parser.parse_args()\n\n    evaluate(\n        args.checkpoint,\n        args.img_base,\n        args.val_transcript,\n        beam_width=args.beam_width\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T14:14:06.882492Z","iopub.execute_input":"2025-11-01T14:14:06.883249Z","iopub.status.idle":"2025-11-01T14:14:06.889491Z","shell.execute_reply.started":"2025-11-01T14:14:06.883217Z","shell.execute_reply":"2025-11-01T14:14:06.888743Z"}},"outputs":[{"name":"stdout","text":"Overwriting src/eval.py\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python src/train.py --config configs/default.yaml\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:50:57.701910Z","iopub.execute_input":"2025-11-01T12:50:57.702450Z","iopub.status.idle":"2025-11-01T13:43:39.510970Z","shell.execute_reply.started":"2025-11-01T12:50:57.702426Z","shell.execute_reply":"2025-11-01T13:43:39.510159Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/Handwriting/src/train.py:67: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\nEpoch 1/30 [Train]:   0%|                               | 0/811 [00:00<?, ?it/s]/kaggle/working/Handwriting/src/train.py:83: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\nEpoch 1/30 [Train]: 100%|███████████| 811/811 [01:38<00:00,  8.22it/s, loss=2.9]\n\nEpoch 1 | Avg Train Loss: 3.8845 | LR: 0.000069\nEpoch 1 [Val]:   0%|                                    | 0/122 [00:00<?, ?it/s]/kaggle/working/Handwriting/src/train.py:116: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\nEpoch 1 [Val]: 100%|██████████████████████████| 122/122 [00:07<00:00, 17.35it/s]\nEpoch 1 | Val CER: 1.0000 | Val WER: 1.0000\n✅ Saved best checkpoint at checkpoints/best.pt (CER=1.0000)\nEpoch 2/30 [Train]: 100%|██████████| 811/811 [01:38<00:00,  8.21it/s, loss=1.92]\n\nEpoch 2 | Avg Train Loss: 2.5231 | LR: 0.000152\nEpoch 2 [Val]: 100%|██████████████████████████| 122/122 [00:07<00:00, 17.40it/s]\nEpoch 2 | Val CER: 0.5859 | Val WER: 0.9062\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.5859)\nEpoch 3/30 [Train]: 100%|█████████| 811/811 [01:38<00:00,  8.25it/s, loss=0.632]\n\nEpoch 3 | Avg Train Loss: 1.1002 | LR: 0.000280\nEpoch 3 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.56it/s]\nEpoch 3 | Val CER: 0.1760 | Val WER: 0.5455\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.1760)\nEpoch 4/30 [Train]: 100%|██████████| 811/811 [01:38<00:00,  8.27it/s, loss=0.54]\n\nEpoch 4 | Avg Train Loss: 0.5840 | LR: 0.000437\nEpoch 4 [Val]: 100%|██████████████████████████| 122/122 [00:07<00:00, 17.36it/s]\nEpoch 4 | Val CER: 0.1425 | Val WER: 0.4645\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.1425)\nEpoch 5/30 [Train]: 100%|█████████| 811/811 [01:38<00:00,  8.28it/s, loss=0.439]\n\nEpoch 5 | Avg Train Loss: 0.4471 | LR: 0.000603\nEpoch 5 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.56it/s]\nEpoch 5 | Val CER: 0.1349 | Val WER: 0.4216\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.1349)\nEpoch 6/30 [Train]: 100%|█████████| 811/811 [01:37<00:00,  8.29it/s, loss=0.383]\n\nEpoch 6 | Avg Train Loss: 0.3763 | LR: 0.000760\nEpoch 6 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.46it/s]\nEpoch 6 | Val CER: 0.1110 | Val WER: 0.3769\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.1110)\nEpoch 7/30 [Train]: 100%|█████████| 811/811 [01:37<00:00,  8.29it/s, loss=0.243]\n\nEpoch 7 | Avg Train Loss: 0.3288 | LR: 0.000888\nEpoch 7 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.46it/s]\nEpoch 7 | Val CER: 0.1040 | Val WER: 0.3519\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.1040)\nEpoch 8/30 [Train]: 100%|█████████| 811/811 [01:38<00:00,  8.25it/s, loss=0.895]\n\nEpoch 8 | Avg Train Loss: 0.2995 | LR: 0.000971\nEpoch 8 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.51it/s]\nEpoch 8 | Val CER: 0.0993 | Val WER: 0.3360\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0993)\nEpoch 9/30 [Train]: 100%|█████████| 811/811 [01:37<00:00,  8.28it/s, loss=0.129]\n\nEpoch 9 | Avg Train Loss: 0.2777 | LR: 0.001000\nEpoch 9 [Val]: 100%|██████████████████████████| 122/122 [00:06<00:00, 17.57it/s]\nEpoch 9 | Val CER: 0.2125 | Val WER: 0.5687\nEpoch 10/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.26it/s, loss=0.0852]\n\nEpoch 10 | Avg Train Loss: 0.2592 | LR: 0.000994\nEpoch 10 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.46it/s]\nEpoch 10 | Val CER: 0.0932 | Val WER: 0.3178\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0932)\nEpoch 11/30 [Train]: 100%|████████| 811/811 [01:38<00:00,  8.26it/s, loss=0.225]\n\nEpoch 11 | Avg Train Loss: 0.2380 | LR: 0.000978\nEpoch 11 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.54it/s]\nEpoch 11 | Val CER: 0.0961 | Val WER: 0.3229\nEpoch 12/30 [Train]: 100%|████████| 811/811 [01:38<00:00,  8.26it/s, loss=0.041]\n\nEpoch 12 | Avg Train Loss: 0.2345 | LR: 0.000950\nEpoch 12 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.44it/s]\nEpoch 12 | Val CER: 0.0969 | Val WER: 0.3279\nEpoch 13/30 [Train]: 100%|████████| 811/811 [01:37<00:00,  8.28it/s, loss=0.173]\n\nEpoch 13 | Avg Train Loss: 0.2185 | LR: 0.000913\nEpoch 13 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.56it/s]\nEpoch 13 | Val CER: 0.0882 | Val WER: 0.3005\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0882)\nEpoch 14/30 [Train]: 100%|█████████| 811/811 [01:38<00:00,  8.24it/s, loss=0.52]\n\nEpoch 14 | Avg Train Loss: 0.2021 | LR: 0.000866\nEpoch 14 [Val]: 100%|█████████████████████████| 122/122 [00:07<00:00, 17.37it/s]\nEpoch 14 | Val CER: 0.0875 | Val WER: 0.3038\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0875)\nEpoch 15/30 [Train]: 100%|████████| 811/811 [01:38<00:00,  8.27it/s, loss=0.145]\n\nEpoch 15 | Avg Train Loss: 0.1868 | LR: 0.000812\nEpoch 15 [Val]: 100%|█████████████████████████| 122/122 [00:07<00:00, 17.40it/s]\nEpoch 15 | Val CER: 0.0820 | Val WER: 0.2810\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0820)\nEpoch 16/30 [Train]: 100%|████████| 811/811 [01:38<00:00,  8.25it/s, loss=0.404]\n\nEpoch 16 | Avg Train Loss: 0.1687 | LR: 0.000750\nEpoch 16 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.45it/s]\nEpoch 16 | Val CER: 0.0845 | Val WER: 0.2903\nEpoch 17/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.26it/s, loss=0.0655]\n\nEpoch 17 | Avg Train Loss: 0.1488 | LR: 0.000683\nEpoch 17 [Val]: 100%|█████████████████████████| 122/122 [00:07<00:00, 17.42it/s]\nEpoch 17 | Val CER: 0.0786 | Val WER: 0.2735\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0786)\nEpoch 18/30 [Train]: 100%|████████| 811/811 [01:37<00:00,  8.30it/s, loss=0.245]\n\nEpoch 18 | Avg Train Loss: 0.1295 | LR: 0.000611\nEpoch 18 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.58it/s]\nEpoch 18 | Val CER: 0.0730 | Val WER: 0.2610\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0730)\nEpoch 19/30 [Train]: 100%|███████| 811/811 [01:37<00:00,  8.28it/s, loss=0.0692]\n\nEpoch 19 | Avg Train Loss: 0.1113 | LR: 0.000537\nEpoch 19 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.55it/s]\nEpoch 19 | Val CER: 0.0761 | Val WER: 0.2668\nEpoch 20/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.26it/s, loss=0.0358]\n\nEpoch 20 | Avg Train Loss: 0.0926 | LR: 0.000463\nEpoch 20 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.50it/s]\nEpoch 20 | Val CER: 0.0703 | Val WER: 0.2480\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0703)\nEpoch 21/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.27it/s, loss=0.0857]\n\nEpoch 21 | Avg Train Loss: 0.0754 | LR: 0.000389\nEpoch 21 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.52it/s]\nEpoch 21 | Val CER: 0.0690 | Val WER: 0.2429\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0690)\nEpoch 22/30 [Train]: 100%|██████| 811/811 [01:38<00:00,  8.27it/s, loss=0.00678]\n\nEpoch 22 | Avg Train Loss: 0.0590 | LR: 0.000317\nEpoch 22 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.50it/s]\nEpoch 22 | Val CER: 0.0661 | Val WER: 0.2367\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0661)\nEpoch 23/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.27it/s, loss=0.0248]\n\nEpoch 23 | Avg Train Loss: 0.0450 | LR: 0.000250\nEpoch 23 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.57it/s]\nEpoch 23 | Val CER: 0.0665 | Val WER: 0.2381\nEpoch 24/30 [Train]: 100%|██████| 811/811 [01:37<00:00,  8.29it/s, loss=0.00364]\n\nEpoch 24 | Avg Train Loss: 0.0336 | LR: 0.000188\nEpoch 24 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.53it/s]\nEpoch 24 | Val CER: 0.0644 | Val WER: 0.2296\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0644)\nEpoch 25/30 [Train]: 100%|███████| 811/811 [01:38<00:00,  8.27it/s, loss=0.0176]\n\nEpoch 25 | Avg Train Loss: 0.0238 | LR: 0.000133\nEpoch 25 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.45it/s]\nEpoch 25 | Val CER: 0.0634 | Val WER: 0.2286\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0634)\nEpoch 26/30 [Train]: 100%|████████| 811/811 [01:38<00:00,  8.28it/s, loss=0.184]\n\nEpoch 26 | Avg Train Loss: 0.0181 | LR: 0.000087\nEpoch 26 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.51it/s]\nEpoch 26 | Val CER: 0.0626 | Val WER: 0.2264\n✅ Saved best checkpoint at checkpoints/best.pt (CER=0.0626)\nEpoch 27/30 [Train]: 100%|███████| 811/811 [01:37<00:00,  8.30it/s, loss=0.0232]\n\nEpoch 27 | Avg Train Loss: 0.0137 | LR: 0.000049\nEpoch 27 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.49it/s]\nEpoch 27 | Val CER: 0.0631 | Val WER: 0.2274\nEpoch 28/30 [Train]: 100%|███████| 811/811 [01:37<00:00,  8.29it/s, loss=0.0157]\n\nEpoch 28 | Avg Train Loss: 0.0115 | LR: 0.000022\nEpoch 28 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.49it/s]\nEpoch 28 | Val CER: 0.0630 | Val WER: 0.2260\nEpoch 29/30 [Train]: 100%|███████| 811/811 [01:37<00:00,  8.28it/s, loss=0.0604]\n\nEpoch 29 | Avg Train Loss: 0.0101 | LR: 0.000006\nEpoch 29 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.52it/s]\nEpoch 29 | Val CER: 0.0629 | Val WER: 0.2278\nEpoch 30/30 [Train]: 100%|██████| 811/811 [01:37<00:00,  8.30it/s, loss=0.00161]\n\nEpoch 30 | Avg Train Loss: 0.0092 | LR: 0.000000\nEpoch 30 [Val]: 100%|█████████████████████████| 122/122 [00:06<00:00, 17.54it/s]\nEpoch 30 | Val CER: 0.0628 | Val WER: 0.2257\n\nTraining completed successfully ✅\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!python src/eval.py --checkpoint checkpoints/best.pt #--beam_width 10\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T14:13:41.971783Z","iopub.execute_input":"2025-11-01T14:13:41.972044Z","iopub.status.idle":"2025-11-01T14:13:57.494530Z","shell.execute_reply.started":"2025-11-01T14:13:41.972025Z","shell.execute_reply":"2025-11-01T14:13:57.493565Z"}},"outputs":[{"name":"stdout","text":"Evaluating: 100%|█████████████████████████████| 122/122 [00:11<00:00, 10.46it/s]\nAverage CER: 0.0626\nAverage WER: 0.2265\nSequence Accuracy: 0.2049\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!python src/eval.py --checkpoint checkpoints/best.pt --beam_width 10\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T14:14:12.791720Z","iopub.execute_input":"2025-11-01T14:14:12.792454Z","iopub.status.idle":"2025-11-01T14:14:16.151144Z","shell.execute_reply.started":"2025-11-01T14:14:12.792430Z","shell.execute_reply":"2025-11-01T14:14:16.150410Z"}},"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/kaggle/working/Handwriting/src/eval.py\", line 16, in <module>\n    from src.utils.beam_search import beam_search_decode  # ✅ Added import\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nModuleNotFoundError: No module named 'src.utils.beam_search'\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!python src/eval.py --checkpoint checkpoints/best.pt --beam_width 5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.669060Z","iopub.status.idle":"2025-11-01T12:45:56.669357Z","shell.execute_reply.started":"2025-11-01T12:45:56.669205Z","shell.execute_reply":"2025-11-01T12:45:56.669218Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python src/eval.py --checkpoint checkpoints/best.pt --beam_width 15\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.670862Z","iopub.status.idle":"2025-11-01T12:45:56.671163Z","shell.execute_reply.started":"2025-11-01T12:45:56.671041Z","shell.execute_reply":"2025-11-01T12:45:56.671054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from jiwer import wer, cer\n\npreds = [\"this is a test\", \"hello world\"]\ntargets = [\"this is test\", \"hello word\"]\n\nprint(\"CER:\", cer(targets, preds))\nprint(\"WER:\", wer(targets, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.672387Z","iopub.status.idle":"2025-11-01T12:45:56.672625Z","shell.execute_reply.started":"2025-11-01T12:45:56.672514Z","shell.execute_reply":"2025-11-01T12:45:56.672527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# download as zip file\n#!zip -r handwriting_repo.zip Handwriting_pipeline\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.673560Z","iopub.status.idle":"2025-11-01T12:45:56.673855Z","shell.execute_reply.started":"2025-11-01T12:45:56.673723Z","shell.execute_reply":"2025-11-01T12:45:56.673741Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#after uploading zip file run below to unzip\n# !unzip /kaggle/input/HandWriting_001 -d /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T12:45:56.675266Z","iopub.status.idle":"2025-11-01T12:45:56.675541Z","shell.execute_reply.started":"2025-11-01T12:45:56.675386Z","shell.execute_reply":"2025-11-01T12:45:56.675399Z"}},"outputs":[],"execution_count":null}]}